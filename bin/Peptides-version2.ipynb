{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "Before running this, make sure that all prerequisites are installed. This is done by running \n",
    "\n",
    "$ pip install -r requirements.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import Bio as bio\n",
    "from Bio import SeqIO\n",
    "import random\n",
    "import scipy\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "import os\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POSITIVE_TM_PATH = \"../data/training_data/positive_examples/tm\"\n",
    "POSITIVE_NON_TM_PATH = \"../data/training_data/positive_examples/non_tm\"\n",
    "NEGATIVE_TM_PATH = \"../data/training_data/negative_examples/tm\"\n",
    "NEGATIVE_NON_TM_PATH = \"../data/training_data/negative_examples/non_tm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_tm = [seq for path in os.listdir(POSITIVE_TM_PATH) \n",
    "                       for seq in SeqIO.parse(os.path.join(POSITIVE_TM_PATH, path), \"fasta\")]\n",
    "\n",
    "positive_non_tm = [seq for path in os.listdir(POSITIVE_NON_TM_PATH) \n",
    "                       for seq in SeqIO.parse(os.path.join(POSITIVE_NON_TM_PATH, path), \"fasta\")]\n",
    "\n",
    "negative_tm = [seq for path in os.listdir(NEGATIVE_TM_PATH) \n",
    "                       for seq in SeqIO.parse(os.path.join(NEGATIVE_TM_PATH, path), \"fasta\")]\n",
    "               \n",
    "negative_non_tm = [seq for path in os.listdir(NEGATIVE_NON_TM_PATH) \n",
    "                       for seq in SeqIO.parse(os.path.join(NEGATIVE_NON_TM_PATH, path), \"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positives, tm: 45\n",
      "positives, non_tm: 1275\n",
      "negavtive, tm: 247\n",
      "negavtive, non_tm: 1087\n"
     ]
    }
   ],
   "source": [
    "print(\"positives, tm:\",  len(positive_tm))\n",
    "print(\"positives, non_tm:\",  len(positive_non_tm))\n",
    "print(\"negavtive, tm:\",  len(negative_tm))\n",
    "print(\"negavtive, non_tm:\", len( negative_non_tm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "positive = positive_tm + positive_non_tm\n",
    "negative = negative_tm + negative_non_tm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positives 1320\n",
      "negavtive 1334\n",
      "x shape (2654,)\n",
      "x shape (2654,)\n"
     ]
    }
   ],
   "source": [
    "print(\"positives\",  len(positive))\n",
    "print(\"negavtive\",  len(negative))\n",
    "x = np.array(positive + negative)\n",
    "y = np.array([1]*len(positive) + [0]*len(negative))\n",
    "\n",
    "assert x.shape == y.shape, \"There should be one lable for every datapoint\"\n",
    "print(\"x shape\",  x.shape)\n",
    "print(\"x shape\",  y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_seq, X_test_seq, Y_train, Y_test = cross_validation.train_test_split(x, y, random_state=7, train_size=0.9)\n",
    "\n",
    "def vector_to_onehot(vector, vocabulary_size):\n",
    "    matrix = np.zeros((vector.shape[0], vocabulary_size))\n",
    "    for i, j in enumerate(vector):\n",
    "        matrix[i, j] = 1\n",
    "    return matrix \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding sequences to length 143\n",
      "X_train_padded shape (2388, 143)\n",
      "Z_train_padded shape (2388, 143)\n",
      "X_test_padded shape (266, 143)\n",
      "Z_test_padded shape (266, 143)\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "X_train = [[ord(c)-65 for c in str(seq.seq).split('#')[0].strip()] for seq in X_train_seq ]\n",
    "Z_train = [[ord(c.upper())-65 for c in str(seq.seq).split('#')[0].strip()] for seq in X_train_seq ]\n",
    "X_test = [[ord(c)-65 for c in str(seq.seq).split('#')[0].strip()] for seq in X_test_seq ]\n",
    "Z_test = [[ord(c.upper())-65 for c in str(seq.seq).split('#')[1].strip()] for seq in X_test_seq ]\n",
    "\n",
    "max_len = [len(s) for s in X_train][-20]\n",
    "print(\"Padding sequences to length {}\".format(max_len))\n",
    "X_train_padded = sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "Z_train_padded = sequence.pad_sequences(X_train, maxlen=max_len)\n",
    "X_test_padded = sequence.pad_sequences(X_test, maxlen=max_len)\n",
    "Z_test_padded = sequence.pad_sequences(Z_test, maxlen=max_len)\n",
    "\n",
    "print(\"X_train_padded shape\", X_train_padded.shape)\n",
    "print(\"Z_train_padded shape\", Z_train_padded.shape)\n",
    "print(\"X_test_padded shape\", X_test_padded.shape)\n",
    "print(\"Z_test_padded shape\", Z_test_padded.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_onehot = np.array([ vector_to_onehot(seq, 27) for seq in X_train_padded])\n",
    "Z_train_onehot = np.array([ vector_to_onehot(seq, 27) for seq in Z_train_padded])\n",
    "X_test_onehot = np.array([ vector_to_onehot(seq, 27) for seq in X_test_padded])\n",
    "Z_test_onehot = np.array([ vector_to_onehot(seq, 27) for seq in Z_test_padded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2388, 143, 27)\n",
      "(2388, 143, 27)\n",
      "(266, 143, 27)\n",
      "(266, 143, 27)\n"
     ]
    }
   ],
   "source": [
    "np.swapaxes(X_train_onehot, 0, 1)\n",
    "np.swapaxes(Z_train_onehot, 0, 1)\n",
    "np.swapaxes(X_test_onehot, 0, 1)\n",
    "np.swapaxes(Z_test_onehot , 0, 1)\n",
    "print(X_train_onehot.shape)\n",
    "print(Z_train_onehot.shape)\n",
    "print(X_test_onehot.shape)\n",
    "print(Z_test_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "lstm_37 (LSTM)                   (None, 50)            15600       lstm_input_35[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 50)            0           lstm_37[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 143)           7293        dropout_4[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 22893\n",
      "____________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Error when checking model target: expected dense_4 to have 2 dimensions, but got array with shape (2388, 143, 27)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-102-4f7aa6c4380c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ_train_onehot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m                               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m                               sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight)\u001b[0m\n\u001b[1;32m   1032\u001b[0m                                                            \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m                                                            \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                                                            batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# prepare validation data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_dim, batch_size)\u001b[0m\n\u001b[1;32m    963\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                                    \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                                    exception_prefix='model target')\n\u001b[0m\u001b[1;32m    966\u001b[0m         sample_weights = standardize_sample_weights(sample_weight,\n\u001b[1;32m    967\u001b[0m                                                     self.output_names)\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_dim, exception_prefix)\u001b[0m\n\u001b[1;32m     95\u001b[0m                                 \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                                 \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                                 str(array.shape))\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_dim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Error when checking model target: expected dense_4 to have 2 dimensions, but got array with shape (2388, 143, 27)"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(X_train_onehot.shape[1], X_train_onehot.shape[2])))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Z_train_onehot.shape[1], activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "print(model.summary())\n",
    "\n",
    "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.fit(X_train_onehot, Z_train_onehot, nb_epoch=20, batch_size=128, callbacks=callbacks_list)\n",
    "\n",
    "model.fit(X, y, nb_epoch=20, batch_size=128, callbacks=callbacks_list)\n",
    "\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(X_test_onehot, Z_test_onehot, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "model_json = model.to_json()\n",
    "with open(\"../results/seq2seq/{}.json\".format(datetime.today().strftime(\"%d_%m_%Y_%I:%M%p\")),  \"w+\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"../results/seq/{}.h5\".format(datetime.today().strftime(\"%d_%m_%Y_%I:%M%p\")))\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test_onehot, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--\n",
      "4\n",
      "14\n",
      "--\n",
      "--\n",
      "10\n",
      "14\n",
      "--\n",
      "--\n",
      "19\n",
      "14\n",
      "--\n",
      "--\n",
      "17\n",
      "14\n",
      "--\n",
      "--\n",
      "8\n",
      "14\n",
      "--\n",
      "--\n",
      "6\n",
      "14\n",
      "--\n",
      "--\n",
      "13\n",
      "14\n",
      "--\n",
      "--\n",
      "6\n",
      "14\n",
      "--\n",
      "--\n",
      "21\n",
      "14\n",
      "--\n",
      "--\n",
      "24\n",
      "14\n",
      "--\n",
      "--\n",
      "16\n",
      "14\n",
      "--\n",
      "--\n",
      "5\n",
      "14\n",
      "--\n",
      "--\n",
      "10\n",
      "14\n",
      "--\n",
      "--\n",
      "8\n",
      "14\n",
      "--\n",
      "--\n",
      "6\n",
      "14\n",
      "--\n",
      "--\n",
      "4\n",
      "14\n",
      "--\n",
      "--\n",
      "21\n",
      "14\n",
      "--\n",
      "--\n",
      "21\n",
      "14\n",
      "--\n",
      "--\n",
      "3\n",
      "14\n",
      "--\n",
      "--\n",
      "21\n",
      "14\n",
      "--\n",
      "--\n",
      "8\n",
      "14\n",
      "--\n",
      "--\n",
      "11\n",
      "14\n",
      "--\n",
      "--\n",
      "16\n",
      "14\n",
      "--\n",
      "--\n",
      "13\n",
      "14\n",
      "--\n",
      "--\n",
      "0\n",
      "14\n",
      "--\n",
      "--\n",
      "13\n",
      "14\n",
      "--\n",
      "--\n",
      "12\n",
      "14\n",
      "--\n",
      "--\n",
      "12\n",
      "14\n",
      "--\n",
      "--\n",
      "10\n",
      "14\n",
      "--\n",
      "--\n",
      "4\n",
      "14\n",
      "--\n",
      "--\n",
      "13\n",
      "14\n",
      "--\n",
      "--\n",
      "11\n",
      "14\n",
      "--\n",
      "--\n",
      "18\n",
      "14\n",
      "--\n",
      "--\n",
      "4\n",
      "14\n",
      "--\n",
      "--\n",
      "19\n",
      "14\n",
      "--\n",
      "--\n",
      "7\n",
      "14\n",
      "--\n",
      "--\n",
      "15\n",
      "14\n",
      "--\n",
      "--\n",
      "22\n",
      "14\n",
      "--\n",
      "--\n",
      "7\n",
      "14\n",
      "--\n",
      "--\n",
      "11\n",
      "14\n",
      "--\n",
      "--\n",
      "7\n",
      "14\n",
      "--\n",
      "--\n",
      "6\n",
      "14\n",
      "--\n",
      "--\n",
      "7\n",
      "14\n",
      "--\n",
      "--\n",
      "3\n",
      "14\n",
      "--\n",
      "--\n",
      "5\n",
      "14\n",
      "--\n",
      "--\n",
      "22\n",
      "14\n",
      "--\n",
      "--\n",
      "21\n",
      "14\n",
      "--\n",
      "--\n",
      "11\n",
      "14\n",
      "--\n",
      "--\n",
      "6\n",
      "14\n",
      "--\n",
      "--\n",
      "24\n",
      "14\n",
      "--\n",
      "--\n",
      "6\n",
      "14\n",
      "--\n",
      "--\n",
      "3\n",
      "14\n",
      "--\n",
      "--\n",
      "6\n",
      "14\n",
      "--\n",
      "--\n",
      "10\n",
      "14\n",
      "--\n",
      "--\n",
      "5\n",
      "14\n",
      "--\n",
      "--\n",
      "18\n",
      "14\n",
      "--\n",
      "--\n",
      "0\n",
      "14\n",
      "--\n",
      "--\n",
      "4\n",
      "14\n",
      "--\n",
      "--\n",
      "4\n",
      "14\n",
      "--\n",
      "--\n",
      "4\n",
      "14\n",
      "--\n",
      "--\n",
      "18\n",
      "14\n",
      "--\n",
      "--\n",
      "18\n",
      "14\n",
      "--\n",
      "--\n",
      "11\n",
      "14\n",
      "--\n",
      "--\n",
      "13\n",
      "14\n",
      "--\n",
      "--\n",
      "11\n",
      "14\n",
      "--\n",
      "--\n",
      "10\n",
      "14\n",
      "--\n",
      "--\n",
      "13\n",
      "14\n",
      "--\n",
      "--\n",
      "15\n",
      "14\n",
      "--\n",
      "--\n",
      "15\n",
      "14\n",
      "--\n",
      "--\n",
      "11\n",
      "14\n",
      "--\n",
      "--\n",
      "17\n",
      "14\n",
      "--\n",
      "--\n",
      "13\n",
      "14\n",
      "--\n",
      "--\n",
      "19\n",
      "14\n",
      "--\n",
      "--\n",
      "21\n",
      "14\n",
      "--\n",
      "--\n",
      "21\n",
      "14\n",
      "--\n",
      "--\n",
      "8\n",
      "14\n",
      "--\n",
      "--\n",
      "5\n",
      "14\n",
      "--\n",
      "--\n",
      "15\n",
      "14\n",
      "--\n",
      "--\n",
      "24\n",
      "14\n",
      "--\n",
      "--\n",
      "6\n",
      "14\n",
      "--\n",
      "--\n",
      "22\n",
      "14\n",
      "--\n",
      "--\n",
      "19\n",
      "14\n",
      "--\n",
      "--\n",
      "0\n",
      "14\n",
      "--\n",
      "--\n",
      "8\n",
      "14\n",
      "--\n",
      "--\n",
      "17\n",
      "14\n",
      "--\n",
      "--\n",
      "5\n",
      "14\n",
      "--\n",
      "--\n",
      "21\n",
      "14\n",
      "--\n",
      "--\n",
      "0\n",
      "14\n",
      "--\n",
      "--\n",
      "3\n",
      "14\n",
      "--\n",
      "--\n",
      "13\n",
      "14\n",
      "--\n",
      "--\n",
      "15\n",
      "14\n",
      "--\n",
      "--\n",
      "6\n",
      "14\n",
      "--\n",
      "--\n",
      "21\n",
      "14\n",
      "--\n",
      "--\n",
      "22\n",
      "14\n",
      "--\n",
      "--\n",
      "0\n",
      "14\n",
      "--\n",
      "--\n",
      "5\n",
      "14\n",
      "--\n",
      "--\n",
      "7\n",
      "14\n",
      "--\n",
      "--\n",
      "2\n",
      "14\n",
      "--\n",
      "--\n",
      "7\n",
      "14\n",
      "--\n",
      "--\n",
      "8\n",
      "14\n",
      "--\n",
      "--\n",
      "4\n",
      "14\n",
      "--\n",
      "--\n",
      "15\n",
      "14\n",
      "--\n",
      "--\n",
      "7\n",
      "14\n",
      "--\n",
      "--\n",
      "11\n",
      "14\n",
      "--\n",
      "--\n",
      "7\n",
      "14\n",
      "--\n",
      "--\n",
      "12\n",
      "14\n",
      "--\n",
      "--\n",
      "6\n",
      "14\n",
      "--\n",
      "--\n",
      "12\n",
      "14\n",
      "--\n",
      "--\n",
      "6\n",
      "14\n",
      "--\n",
      "--\n",
      "21\n",
      "14\n",
      "--\n",
      "--\n",
      "21\n",
      "14\n",
      "--\n",
      "--\n",
      "5\n",
      "14\n",
      "--\n",
      "--\n",
      "0\n",
      "14\n",
      "--\n",
      "--\n",
      "4\n",
      "14\n",
      "--\n",
      "--\n",
      "6\n",
      "14\n",
      "--\n",
      "--\n",
      "21\n",
      "14\n",
      "--\n",
      "--\n",
      "4\n",
      "14\n",
      "--\n",
      "--\n",
      "10\n",
      "14\n",
      "--\n",
      "--\n",
      "21\n",
      "14\n",
      "--\n",
      "--\n",
      "6\n",
      "14\n",
      "--\n",
      "--\n",
      "17\n",
      "14\n",
      "--\n",
      "--\n",
      "8\n",
      "14\n",
      "--\n",
      "--\n",
      "15\n",
      "14\n",
      "--\n",
      "--\n",
      "19\n",
      "14\n",
      "--\n",
      "--\n",
      "10\n",
      "14\n",
      "--\n",
      "--\n",
      "0\n",
      "14\n",
      "--\n",
      "--\n",
      "11\n",
      "14\n",
      "--\n",
      "--\n",
      "0\n",
      "14\n",
      "--\n",
      "--\n",
      "2\n",
      "14\n",
      "--\n",
      "--\n",
      "6\n",
      "14\n",
      "--\n",
      "--\n",
      "6\n",
      "14\n",
      "--\n",
      "--\n",
      "19\n",
      "14\n",
      "--\n",
      "--\n",
      "0\n",
      "14\n",
      "--\n",
      "--\n",
      "10\n",
      "14\n",
      "--\n",
      "--\n",
      "18\n",
      "14\n",
      "--\n",
      "--\n",
      "11\n",
      "14\n",
      "--\n",
      "--\n",
      "8\n",
      "14\n",
      "--\n",
      "--\n",
      "13\n",
      "14\n",
      "--\n",
      "--\n",
      "13\n",
      "14\n",
      "--\n",
      "--\n",
      "15\n",
      "14\n",
      "--\n",
      "--\n",
      "10\n",
      "14\n",
      "--\n",
      "--\n",
      "13\n",
      "14\n",
      "--\n",
      "--\n",
      "15\n",
      "14\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "for i, m in enumerate(np.argmax(pred[5, :,:], axis=1)):\n",
    "    print(\"--\")\n",
    "    print(m)\n",
    "    print(np.argmax(Z_test_onehot[5, i,:]))\n",
    "    print(\"--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
