{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "Before running this, make sure that all prerequisites are installed. This is done by running \n",
    "\n",
    "$ pip install -r requirements.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import Bio as bio\n",
    "from Bio import SeqIO\n",
    "import random\n",
    "import scipy\n",
    "from hmmlearn import hmm\n",
    "import sklearn\n",
    "from sklearn import cross_validation\n",
    "import os\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POSITIVE_TM_PATH = \"../data/training_data/positive_examples/tm\"\n",
    "POSITIVE_NON_TM_PATH = \"../data/training_data/positive_examples/non_tm\"\n",
    "NEGATIVE_TM_PATH = \"../data/training_data/negative_examples/tm\"\n",
    "NEGATIVE_NON_TM_PATH = \"../data/training_data/negative_examples/non_tm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_tm = [seq for path in os.listdir(POSITIVE_TM_PATH) \n",
    "                       for seq in SeqIO.parse(os.path.join(POSITIVE_TM_PATH, path), \"fasta\")]\n",
    "\n",
    "positive_non_tm = [seq for path in os.listdir(POSITIVE_NON_TM_PATH) \n",
    "                       for seq in SeqIO.parse(os.path.join(POSITIVE_NON_TM_PATH, path), \"fasta\")]\n",
    "\n",
    "negative_tm = [seq for path in os.listdir(NEGATIVE_TM_PATH) \n",
    "                       for seq in SeqIO.parse(os.path.join(NEGATIVE_TM_PATH, path), \"fasta\")]\n",
    "               \n",
    "negative_non_tm = [seq for path in os.listdir(NEGATIVE_NON_TM_PATH) \n",
    "                       for seq in SeqIO.parse(os.path.join(NEGATIVE_NON_TM_PATH, path), \"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positives, tm: 45\n",
      "positives, non_tm: 1275\n",
      "negavtive, tm: 247\n",
      "negavtive, non_tm: 1087\n"
     ]
    }
   ],
   "source": [
    "print(\"positives, tm:\",  len(positive_tm))\n",
    "print(\"positives, non_tm:\",  len(positive_non_tm))\n",
    "print(\"negavtive, tm:\",  len(negative_tm))\n",
    "print(\"negavtive, non_tm:\", len( negative_non_tm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive = positive_tm + positive_non_tm\n",
    "negative = negative_tm + negative_non_tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dataset(dataset, seq_state):\n",
    "    x = np.array([[c for c in str(seq.seq).split('#')[0].strip()] for seq in dataset ])\n",
    "    symbols = { c for seq in x for c in seq}\n",
    "    symbols_map = { s : i for i, s in enumerate(symbols)}\n",
    "    x = np.array(list(map(lambda i : list(map(lambda j: symbols_map[j], i)), x)))\n",
    "\n",
    "    y = [[c for c in str(seq.seq).split('#')[1].strip()] for seq in dataset ]\n",
    "    states = { c for seq in y for c in seq}\n",
    "    state_map = { s : i for i, s in enumerate(states)}\n",
    "    y = np.array(list(map(lambda i : list(map(lambda j: state_map[j], i)), y)))\n",
    "    \n",
    "    n_symbols = len(symbols)\n",
    "    n_states = len(states)\n",
    "\n",
    "    z = np.array([y, seq_state]).T\n",
    "    X_train_seq, X_test_seq, Z_train, Z_test = cross_validation.train_test_split(x, z, random_state=7, train_size=0.6)\n",
    "\n",
    "    assert len(x) == len(y), \"x:{}, y:{}\".format(len(x), len(y))\n",
    "    return X_train_seq, X_test_seq, Z_train, Z_test, n_states, n_symbols, state_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/hmmlearn/hmm.py:405: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(self.emissionprob_)[:, np.concatenate(X)].T\n",
      "/usr/local/lib/python3.5/site-packages/hmmlearn/base.py:451: RuntimeWarning: divide by zero encountered in log\n",
      "  n_samples, n_components, np.log(self.startprob_),\n",
      "/usr/local/lib/python3.5/site-packages/hmmlearn/base.py:452: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.transmat_), framelogprob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9227871939736346\n"
     ]
    }
   ],
   "source": [
    "def hmm_model(X_train_seq, Y_train, n_states, n_symbols):\n",
    "    # Estimate initial matrix\n",
    "    Pi = np.zeros(n_states)\n",
    "    for state_seq in Y_train:\n",
    "        Pi[state_seq[0]] += 1\n",
    "    Pi = Pi/sum(Pi)\n",
    "\n",
    "    # Estimate transition matrix\n",
    "    A = np.zeros((n_states, n_states))\n",
    "    for state_seq in Y_train:\n",
    "        for i in range(len(state_seq)-1):\n",
    "            A[state_seq[i], state_seq[i+1]] += 1\n",
    "\n",
    "    # Normalize transition matrix\n",
    "    for row in range(n_states):\n",
    "        A[row] = A[row]/sum(A[row])\n",
    "\n",
    "    # Estimate emission matrix\n",
    "    B = np.zeros((n_states, n_symbols))\n",
    "    for i, seq in enumerate(X_train_seq):\n",
    "        for j in range(len(seq)):\n",
    "            B[Y_train[i][j], seq[j]] += 1\n",
    "\n",
    "    # Normalize emission matrix\n",
    "    for row in range(n_states):\n",
    "        B[row] = B[row]/sum(B[row])\n",
    "    \n",
    "    model = hmm.MultinomialHMM(n_components=n_states)\n",
    "    model.startprob_ = Pi\n",
    "    model.transmat_ = A\n",
    "    model.emissionprob_ = B\n",
    "    return model\n",
    "\n",
    "dataset = np.array(positive + negative)\n",
    "seq_state = np.array([1]*len(positive) + [0]*len(negative))\n",
    "\n",
    "X_train_seq, X_test_seq, Z_train, Z_test, n_states, n_symbols, state_map = get_dataset(dataset, seq_state) \n",
    "model = hmm_model(X_train_seq, Z_train.T[0], n_states, n_symbols)\n",
    "\n",
    "hit = 0\n",
    "tot = 0\n",
    "for i, seq in enumerate(X_test_seq):\n",
    "    if Z_test[i][1] == 1:\n",
    "        if state_map['C'] in positive_negative_model.predict(np.asmatrix(seq).T):\n",
    "            hit += 1\n",
    "    else:\n",
    "        if state_map['C'] not in positive_negative_model.predict(np.asmatrix(seq).T):\n",
    "            hit += 1\n",
    "    tot += 1\n",
    "print(float(hit)/tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_dataset(dataset):\n",
    "    x = np.array([[c for c in str(seq.seq).split('#')[0].strip()] for seq in dataset ])\n",
    "    symbols = { c for seq in x for c in seq}\n",
    "    symbols_map = { s : i for i, s in enumerate(symbols)}\n",
    "    x = np.array(list(map(lambda i : list(map(lambda j: symbols_map[j], i)), x)))\n",
    "\n",
    "    y = [[c for c in str(seq.seq).split('#')[1].strip()] for seq in dataset ]\n",
    "    states = { c for seq in y for c in seq}\n",
    "    state_map = { s : i for i, s in enumerate(states)}\n",
    "    y = np.array(list(map(lambda i : list(map(lambda j: state_map[j], i)), y)))\n",
    "\n",
    "    n_symbols = len(symbols)\n",
    "    n_states = len(states)\n",
    "    X_train_seq, X_test_seq, Y_train, Y_test = cross_validation.train_test_split(x, y, random_state=7, train_size=0.6)\n",
    "\n",
    "    assert len(x) == len(y), \"x:{}, y:{}\".format(len(x), len(y))\n",
    "    return X_train_seq, X_test_seq, Y_train, Y_test, n_states, n_symbols, state_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/hmmlearn/hmm.py:405: RuntimeWarning: divide by zero encountered in log\n",
      "  return np.log(self.emissionprob_)[:, np.concatenate(X)].T\n",
      "/usr/local/lib/python3.5/site-packages/hmmlearn/base.py:459: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.startprob_),\n",
      "/usr/local/lib/python3.5/site-packages/hmmlearn/base.py:460: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.transmat_),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive: 1.0\n",
      "True negative: 0.25125\n",
      "{'n': 0, 'o': 3, 'h': 4, 'C': 5, 'O': 6, 'i': 1, 'c': 7, 'M': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/hmmlearn/base.py:451: RuntimeWarning: divide by zero encountered in log\n",
      "  n_samples, n_components, np.log(self.startprob_),\n",
      "/usr/local/lib/python3.5/site-packages/hmmlearn/base.py:452: RuntimeWarning: divide by zero encountered in log\n",
      "  np.log(self.transmat_), framelogprob)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9322033898305084\n"
     ]
    }
   ],
   "source": [
    "def hmm_model(X_train_seq, Y_train, n_states, n_symbols):\n",
    "    # Estimate initial matrix\n",
    "    Pi = np.zeros(n_states)\n",
    "    for state_seq in Y_train:\n",
    "        Pi[state_seq[0]] += 1\n",
    "    Pi = Pi/sum(Pi)\n",
    "\n",
    "    # Estimate transition matrix\n",
    "    A = np.zeros((n_states, n_states))\n",
    "    for state_seq in Y_train:\n",
    "        for i in range(len(state_seq)-1):\n",
    "            A[state_seq[i], state_seq[i+1]] += 1\n",
    "\n",
    "    # Normalize transition matrix\n",
    "    for row in range(n_states):\n",
    "        A[row] = A[row]/sum(A[row])\n",
    "\n",
    "    # Estimate emission matrix\n",
    "    B = np.zeros((n_states, n_symbols))\n",
    "    for i, seq in enumerate(X_train_seq):\n",
    "        for j in range(len(seq)):\n",
    "            B[Y_train[i][j], seq[j]] += 1\n",
    "\n",
    "    # Normalize emission matrix\n",
    "    for row in range(n_states):\n",
    "        B[row] = B[row]/sum(B[row])\n",
    "    \n",
    "    model = hmm.MultinomialHMM(n_components=n_states)\n",
    "    model.startprob_ = Pi\n",
    "    model.transmat_ = A\n",
    "    model.emissionprob_ = B\n",
    "    return model\n",
    "\n",
    "def accuracy(dataset, model_1, model_2):\n",
    "    hit = 0\n",
    "    tot = 0\n",
    "    for seq in dataset:\n",
    "        score_1 = model_1.score(np.asmatrix(seq[0]).T)\n",
    "        score_2 = model_2.score(np.asmatrix(seq[0]).T)\n",
    "        if score_1 > score_2:\n",
    "            hit += 1\n",
    "        tot += 1\n",
    "    return float(hit)/tot\n",
    "\n",
    "X_train_seq_p, X_test_seq_p, Y_train_p, Y_test_p, n_states_p, n_symbols_p, state_map_p = get_dataset(positive) \n",
    "positive_model = hmm_model(X_train_seq_p, Y_train_p, n_states_p, n_symbols_p)\n",
    "\n",
    "X_train_seq_n, X_test_seq_n, Y_train_n, Y_test_n, n_states_n, n_symbols_n, state_map_n = get_dataset(negative) \n",
    "negative_model = hmm_model(X_train_seq_n, Y_train_n, n_states_n, n_symbols_n)\n",
    "\n",
    "print(\"True positive:\", accuracy(X_train_seq_p, positive_model, negative_model))\n",
    "print(\"True negative:\", accuracy(X_train_seq_n, negative_model, positive_model))\n",
    "\n",
    "X_train_seq_pn, X_test_seq_pn, Y_train_pn, Y_test_pn, n_states_pn, n_symbols_pn, state_map_pn = get_dataset(positive + negative) \n",
    "positive_negative_model = hmm_model(X_train_seq_pn, Y_train_pn, n_states_pn, n_symbols_pn)\n",
    "print(state_map_pn)\n",
    "\n",
    "\n",
    "hit = 0\n",
    "tot = 0\n",
    "for seq_p in X_test_seq_p:\n",
    "    if state_map_pn['C'] in positive_negative_model.predict(np.asmatrix(seq_p).T):\n",
    "        hit += 1\n",
    "    tot += 1\n",
    "\n",
    "for seq_n in X_test_seq_n:\n",
    "    if state_map_pn['C'] not in positive_negative_model.predict(np.asmatrix(seq_n).T):\n",
    "        hit += 1\n",
    "    tot += 1\n",
    "    \n",
    "print(float(hit)/tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
