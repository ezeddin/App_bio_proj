{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project\n",
    "\n",
    "Before running this, make sure that all prerequisites are installed. This is done by running \n",
    "\n",
    "$ pip install -r requirements.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sklearn\n",
    "import Bio as bio\n",
    "import numpy as np\n",
    "from Bio import SeqIO\n",
    "from hmmlearn import hmm\n",
    "from sklearn import cross_validation\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "SEED = 1337\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POSITIVE_TM_PATH = \"../data/training_data/positive_examples/tm\"\n",
    "POSITIVE_NON_TM_PATH = \"../data/training_data/positive_examples/non_tm\"\n",
    "NEGATIVE_TM_PATH = \"../data/training_data/negative_examples/tm\"\n",
    "NEGATIVE_NON_TM_PATH = \"../data/training_data/negative_examples/non_tm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive_tm = [seq for path in os.listdir(POSITIVE_TM_PATH) \n",
    "                       for seq in SeqIO.parse(os.path.join(POSITIVE_TM_PATH, path), \"fasta\")]\n",
    "\n",
    "positive_non_tm = [seq for path in os.listdir(POSITIVE_NON_TM_PATH) \n",
    "                       for seq in SeqIO.parse(os.path.join(POSITIVE_NON_TM_PATH, path), \"fasta\")]\n",
    "\n",
    "negative_tm = [seq for path in os.listdir(NEGATIVE_TM_PATH) \n",
    "                       for seq in SeqIO.parse(os.path.join(NEGATIVE_TM_PATH, path), \"fasta\")]\n",
    "               \n",
    "negative_non_tm = [seq for path in os.listdir(NEGATIVE_NON_TM_PATH) \n",
    "                       for seq in SeqIO.parse(os.path.join(NEGATIVE_NON_TM_PATH, path), \"fasta\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positives, tm: 45\n",
      "positives, non_tm: 1275\n",
      "negavtive, tm: 247\n",
      "negavtive, non_tm: 1087\n"
     ]
    }
   ],
   "source": [
    "print(\"positives, tm:\",  len(positive_tm))\n",
    "print(\"positives, non_tm:\",  len(positive_non_tm))\n",
    "print(\"negavtive, tm:\",  len(negative_tm))\n",
    "print(\"negavtive, non_tm:\", len( negative_non_tm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "positive = positive_tm + positive_non_tm\n",
    "negative = negative_tm + negative_non_tm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def encode_data(x, symbols_map=False):\n",
    "    \n",
    "    symbols = { c for seq in x for c in seq}\n",
    "    symbols.update('*')\n",
    "    if not symbols_map:\n",
    "        symbols_map = { s : i for i, s in enumerate(symbols)}\n",
    "    encoded_data = []\n",
    "    for seq in x:\n",
    "        seq_encoded = []\n",
    "        for c in seq:\n",
    "            try:\n",
    "                i = symbols_map[c]\n",
    "            except KeyError:\n",
    "                i = symbols_map['*']\n",
    "            seq_encoded.append(i) \n",
    "        encoded_data.append(seq_encoded)\n",
    "    encoded_data = np.array(encoded_data) \n",
    "            \n",
    "    n_symbols = len(symbols)\n",
    "\n",
    "    return encoded_data, n_symbols, symbols_map\n",
    "\n",
    "def train_and_test_encode(dataset, labels):\n",
    "    x = [[c for c in str(seq.seq).split('#')[0].strip()] for seq in dataset]\n",
    "    x_e, n_symbols, symbols_map = encode_data(x)\n",
    "    z = [[c for c in str(seq.seq).split('#')[1].strip()] for seq in dataset]\n",
    "    z_e, n_states, states_map = encode_data(z)\n",
    "    \n",
    "    X_train, X_test, Z_train, Z_test, train_labels, test_labels = \\\n",
    "        cross_validation.train_test_split(x_e, z_e, labels, random_state=SEED, train_size=.9\n",
    "                                         )\n",
    "    return X_train, X_test, Z_train, Z_test, train_labels, test_labels, n_symbols, n_states, symbols_map, states_map\n",
    "# Produce the \n",
    "def to_states_seq(seq, states_map):\n",
    "    inv_states_map = { v:k for k,v in states_map.items()}\n",
    "    decode = np.vectorize(lambda x: inv_states_map[x])\n",
    "    print(decode(model.predict(np.asmatrix(seq).T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hmm_model(X_train_seq, Y_train, n_states, n_symbols, random_state=None):\n",
    "    \n",
    "    ε = 1e-10\n",
    "    \n",
    "    # Estimate initial matrix\n",
    "    Pi = np.zeros(n_states) + ε\n",
    "    for state_seq in Y_train:\n",
    "        Pi[state_seq[0]] += 1\n",
    "    Pi = Pi/sum(Pi)\n",
    "\n",
    "    # Estimate transition matrix\n",
    "    A = np.zeros((n_states, n_states)) + ε\n",
    "    for state_seq in Y_train:\n",
    "        for i in range(len(state_seq)-1):\n",
    "            A[state_seq[i], state_seq[i+1]] += 1\n",
    "\n",
    "    # Normalize transition matrix\n",
    "    for row in range(n_states):\n",
    "        A[row] = A[row]/sum(A[row])\n",
    "\n",
    "    # Estimate emission matrix\n",
    "    B = np.zeros((n_states, n_symbols)) + ε\n",
    "    for i, seq in enumerate(X_train_seq):\n",
    "        for j in range(len(seq)):\n",
    "            B[Y_train[i][j], seq[j]] += 1\n",
    "\n",
    "    # Normalize emission matrix\n",
    "    for row in range(n_states):\n",
    "        B[row] = B[row]/sum(B[row])\n",
    "    \n",
    "    model = hmm.MultinomialHMM(n_components=n_states, random_state=random_state)\n",
    "    model.startprob_ = Pi\n",
    "    model.transmat_ = A\n",
    "    model.emissionprob_ = B\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = np.array(positive_tm + positive_non_tm + negative_tm + negative_non_tm)\n",
    "labels = np.array([[1,1]]*len(positive_tm) + [[1,0]]*len(positive_non_tm)+[[0,1]]*len(negative_tm) + [[0,0]]*len(negative_non_tm))\n",
    "\n",
    "X_train, X_test, Z_train, Z_test, train_labels, test_labels, n_symbols, n_states, symbols_map, states_map = train_and_test_encode(dataset, labels)\n",
    "model = hmm_model(X_train, Z_train, n_states, n_symbols, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on full data set:\n",
      "Predicting.\n",
      "Done.\n",
      "-------------------\n",
      "All true 127\n",
      "All positive 128\n",
      "True positive 117\n",
      "True negative 128\n",
      "Precission 0.9140625\n",
      "Recal 0.92125984252\n",
      "Accuracy on test data: 92.11%\n",
      "-------------------\n",
      "Evaluated on non-tm:\n",
      "Predicting.\n",
      "Done.\n",
      "-------------------\n",
      "All true 120\n",
      "All positive 118\n",
      "True positive 110\n",
      "True negative 106\n",
      "Precission 0.932203389831\n",
      "Recal 0.916666666667\n",
      "Accuracy on test data: 92.31%\n",
      "-------------------\n",
      "Evaluated on tm:\n",
      "Predicting.\n",
      "Done.\n",
      "-------------------\n",
      "All true 7\n",
      "All positive 10\n",
      "True positive 7\n",
      "True negative 22\n",
      "Precission 0.7\n",
      "Recal 1.0\n",
      "Accuracy on test data: 90.62%\n",
      "-------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(model, test_set, states_map):\n",
    "    res = []\n",
    "    for seq in test_set:\n",
    "        pred_states = model.predict(np.asmatrix(seq).T)\n",
    "        if is_signal(pred_states, states_map):\n",
    "            res.append(1)\n",
    "        else:\n",
    "            res.append(0)\n",
    "    return np.array(res)\n",
    "\n",
    "def is_signal(seq, states_map):\n",
    "    found_set = set()\n",
    "    for c in seq:\n",
    "        if c == states_map['n'] and (not found_set or {'n'} == found_set):\n",
    "            found_set.add('n')\n",
    "        elif c == states_map['h'] and ({'n'} == found_set or {'n','h'} == found_set):\n",
    "            found_set.add('h')\n",
    "        elif c == states_map['c'] and ({'n','h'} == found_set or {'n','h', 'c'} == found_set):\n",
    "            found_set.add('c')\n",
    "        elif c == states_map['C'] and {'n','h', 'c'} == found_set:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    return False\n",
    "            \n",
    "def evaluate(model, test_set, test_labels, states_map):\n",
    "    res = []\n",
    "    print(\"Predicting.\")\n",
    "    prediction = predict(model, test_set, states_map)\n",
    "    print(\"Done.\")\n",
    "    result = test_labels == prediction\n",
    "    true_positive = ((test_labels == 1) & (prediction == 1))\n",
    "    true_negative = ((test_labels == 0) & (prediction == 0))\n",
    "    \n",
    "    print(\"-------------------\")\n",
    "    print(\"All true\", test_labels.sum())\n",
    "    print(\"All positive\", prediction.sum())\n",
    "    print(\"True positive\", true_positive.sum())\n",
    "    print(\"True negative\", true_negative.sum())\n",
    "    print(\"Precission\", (true_positive == 1).sum() / (prediction == 1).sum() )\n",
    "    print(\"Recal\", true_positive.sum() /  test_labels.sum() )\n",
    "    print(\"Accuracy on test data: {:.4}%\".format(result.mean()*100))\n",
    "    print(\"-------------------\")\n",
    "    return prediction\n",
    "          \n",
    "# evaluate all dataset\n",
    "print(\"Evaluated on full data set:\")\n",
    "evaluate(model, X_test, test_labels[:,0], states_map)\n",
    "# evaluate non-tm\n",
    "print(\"Evaluated on non-tm:\")\n",
    "evaluate(model, X_test[test_labels[:,1] == 0], test_labels[test_labels[:,1] == 0][:,0], states_map)\n",
    "# evaluate tm\n",
    "print(\"Evaluated on tm:\")\n",
    "evaluate(model, X_test[test_labels[:,1] == 1], test_labels[test_labels[:,1] == 1][:,0], states_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Import proteomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "HUMAN_PROTEOMS_PATH = \"../data/proteomes/human.fa\"\n",
    "MOUSE_PROTEOMS_PATH = \"../data/proteomes/mouse.fa\"\n",
    "HUMAN_PROTEOMS_SIGNAL_PATH = \"../data/proteomes/human_signal.fa\"\n",
    "MOUSE_PROTEOMS_SIGNAL_PATH = \"../data/proteomes/mouse_signal.fa\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "human_data = np.array([seq for seq in SeqIO.parse(HUMAN_PROTEOMS_PATH, \"fasta\")])\n",
    "mouse_data = np.array([seq for seq in SeqIO.parse(MOUSE_PROTEOMS_PATH, \"fasta\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "human_data_signal = np.array([seq for seq in SeqIO.parse(HUMAN_PROTEOMS_SIGNAL_PATH, \"fasta\")])\n",
    "mouse_data_signal = np.array([seq for seq in SeqIO.parse(MOUSE_PROTEOMS_SIGNAL_PATH, \"fasta\")])\n",
    "human_signal_names = {seq.description for seq in human_data_signal}\n",
    "mouse_signal_names = {seq.description for seq in mouse_data_signal}\n",
    "human_data_labels = np.array([(seq.description in human_signal_names) for seq in human_data])\n",
    "mouse_data_labels = np.array([(seq.description in mouse_signal_names) for seq in mouse_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stats(model, symbols_map, states_map, data, data_signal):\n",
    "    x, n_symbols, _ = encode_data(data, symbols_map)\n",
    "    prediction = predict(model, x, states_map)\n",
    "    all_names = {seq.description for seq in data}\n",
    "    true_names = {seq.description for seq in data_signal}\n",
    "    false_names = all_names - true_names \n",
    "    positive_names = {seq.description for seq in np.array(data)[prediction == 1]}\n",
    "    negative_names = {seq.description for seq in np.array(data)[prediction == 0]}\n",
    "\n",
    "    precision = len(true_names & positive_names) / len(positive_names)\n",
    "    recall = len(true_names & positive_names) / len(true_names)\n",
    "    \n",
    "    print(\"Predicted signal peptides: {:.4}%\".format(np.array(prediction).mean()*100))\n",
    "    print(\"Accuracy: {:.4}\".format(len((true_names & positive_names)|((false_names & negative_names))) / len(all_names)))\n",
    "    print('Precision: {:.4}'.format(precision))\n",
    "    print('Recall: {:.4}'.format(recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUMAN\n"
     ]
    }
   ],
   "source": [
    "print('HUMAN')\n",
    "encoded_data_human, n_symbols, _ = encode_data(np.array(human_data), symbols_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting.\n",
      "Done.\n",
      "-------------------\n",
      "All true 12931\n",
      "All positive 17181\n",
      "True positive 10626\n",
      "True negative 196443\n",
      "Precission 0.618473895582\n",
      "Recal 0.821746191323\n",
      "Accuracy on test data: 95.9%\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "human_prediction = evaluate(model, encoded_data_human, human_data_labels, states_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MOUSE\n"
     ]
    }
   ],
   "source": [
    "print('MOUSE')\n",
    "encoded_data_mouse, n_symbols, _ = encode_data(np.array(mouse_data), symbols_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting.\n",
      "Done.\n",
      "-------------------\n",
      "All true 7756\n",
      "All positive 9966\n",
      "True positive 6246\n",
      "True negative 112692\n",
      "Precission 0.626730885009\n",
      "Recal 0.805312016503\n",
      "Accuracy on test data: 95.79%\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "mouse_prediction = evaluate(model, encoded_data_mouse, mouse_data_labels, states_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def control_random(seq_len, size=1000):\n",
    "    print(\"Evaluated on random data with length {seq_len}:\".format(seq_len=seq_len))\n",
    "    X_test = np.random.randint(22, size=(size,seq_len))\n",
    "    test_labels = np.zeros(size, dtype=np.int)\n",
    "    test_prediction = evaluate(model, X_test, test_labels, states_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def control_noise(X_test, test_labels, noise_seq_len=1000):\n",
    "    X_test_noise = []\n",
    "    for seq in X_test:\n",
    "        X_test_noise.append(seq + list(np.random.randint(22, size=noise_seq_len)))\n",
    "    print(\"Evaluated on unnoisy data:\".format(seq_len=noise_seq_len))\n",
    "    test_prediction = evaluate(model, X_test, test_labels, states_map) \n",
    "    print()\n",
    "    print(\"Evaluated on noisy data:\".format(seq_len=noise_seq_len))\n",
    "    test_prediction = evaluate(model, X_test_noise, test_labels, states_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_positive = test_labels[:,0] == 1\n",
    "test_negative = test_labels[:,0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Positive -----------\n",
      "Evaluated on unnoisy data:\n",
      "Predicting.\n",
      "Done.\n",
      "-------------------\n",
      "All true 127\n",
      "All positive 117\n",
      "True positive 117\n",
      "True negative 0\n",
      "Precission 1.0\n",
      "Recal 0.92125984252\n",
      "Accuracy on test data: 92.13%\n",
      "-------------------\n",
      "\n",
      "Evaluated on noisy data:\n",
      "Predicting.\n",
      "Done.\n",
      "-------------------\n",
      "All true 127\n",
      "All positive 117\n",
      "True positive 117\n",
      "True negative 0\n",
      "Precission 1.0\n",
      "Recal 0.92125984252\n",
      "Accuracy on test data: 92.13%\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "print('----------- Positive -----------')\n",
    "control_noise(X_test[test_positive], test_labels[test_positive][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Negative -----------\n",
      "Evaluated on unnoisy data:\n",
      "Predicting.\n",
      "Done.\n",
      "-------------------\n",
      "All true 0\n",
      "All positive 11\n",
      "True positive 0\n",
      "True negative 128\n",
      "Precission 0.0\n",
      "Recal nan\n",
      "Accuracy on test data: 92.09%\n",
      "-------------------\n",
      "\n",
      "Evaluated on noisy data:\n",
      "Predicting.\n",
      "Done.\n",
      "-------------------\n",
      "All true 0\n",
      "All positive 11\n",
      "True positive 0\n",
      "True negative 128\n",
      "Precission 0.0\n",
      "Recal nan\n",
      "Accuracy on test data: 92.09%\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "print('----------- Negative -----------')\n",
    "control_noise(X_test[test_negative], test_labels[test_negative][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on random data with length 2:\n",
      "Predicting.\n",
      "Done.\n",
      "-------------------\n",
      "All true 0\n",
      "All positive 0\n",
      "True positive 0\n",
      "True negative 1000\n",
      "Precission nan\n",
      "Recal nan\n",
      "Accuracy on test data: 100.0%\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "control_random(seq_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on random data with length 5:\n",
      "Predicting.\n",
      "Done.\n",
      "-------------------\n",
      "All true 0\n",
      "All positive 2\n",
      "True positive 0\n",
      "True negative 998\n",
      "Precission 0.0\n",
      "Recal nan\n",
      "Accuracy on test data: 99.8%\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "control_random(seq_len=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on random data with length 100:\n",
      "Predicting.\n",
      "Done.\n",
      "-------------------\n",
      "All true 0\n",
      "All positive 110\n",
      "True positive 0\n",
      "True negative 890\n",
      "Precission 0.0\n",
      "Recal nan\n",
      "Accuracy on test data: 89.0%\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "control_random(seq_len=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated on random data with length 10000:\n",
      "Predicting.\n",
      "Done.\n",
      "-------------------\n",
      "All true 0\n",
      "All positive 118\n",
      "True positive 0\n",
      "True negative 882\n",
      "Precission 0.0\n",
      "Recal nan\n",
      "Accuracy on test data: 88.2%\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "control_random(seq_len=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
